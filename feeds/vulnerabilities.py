#!/usr/bin/env python3
# Vulnerability feed processors with unique severity/state filters for
# concurrent execution
import time
from feeds.base import BaseFeedProcessor
from feeds.assets import _safe_export_with_retry


class VulnerabilityFeedProcessor(BaseFeedProcessor):

    def __init__(self, tenable_client, checkpoint_mgr,
                 hec_handler, batch_size=5000, max_events=0):
        super(
            VulnerabilityFeedProcessor,
            self).__init__(
            tenable_client,
            checkpoint_mgr,
            hec_handler,
            "Active Vulnerabilities",
            "tenableio_vulnerability",
            "tenable:io:vulnerability",
            "vulnerability",
            batch_size,
            max_events)

    def process(self):
        self.log_start()
        event_count = 0

        try:
            # Get last processed timestamp for incremental export
            last_timestamp = self.get_last_timestamp()

            self.logger.info(
                "Initiating vulnerability export (severity: medium, high, critical)...")
            self.logger.info(
                "(This may take several minutes for large environments)")

            # Optimized export parameters per Tenable recommendations:
            # - num_assets=2000 (Tenable recommends 1000-3000, default is only 50!)
            # - include_unlicensed=True (capture all assets)
            # - timeout=3600 (1 hour max wait)
            # - since filter for incremental updates
            export_kwargs = {
                'severity': ['medium', 'high', 'critical'],
                'num_assets': 2000,
                'include_unlicensed': True,
                'timeout': 3600
            }

            # Use 'since' filter for incremental export
            if last_timestamp and last_timestamp > 0:
                export_kwargs['since'] = int(last_timestamp)
                self.logger.info(
                    "Incremental export since: {0}".format(last_timestamp))
            else:
                self.logger.info("Full export (no previous checkpoint)")

            latest_timestamp = last_timestamp or 0
            current_time = int(time.time())

            for vuln in _safe_export_with_retry(
                lambda: self.tenable.exports.vulns(**export_kwargs),
                "Active Vulnerabilities"
            ):
                vuln_key = "{0}_{1}_{2}_{3}".format(
                    vuln.get('asset', {}).get('uuid', 'unknown'),
                    vuln.get('plugin', {}).get('id', 'unknown'),
                    vuln.get('port', {}).get('port', '0'),
                    vuln.get('port', {}).get('protocol', 'tcp')
                )

                if self.is_processed(vuln_key):
                    continue

                if self.send_event(vuln, item_id=vuln_key):
                    event_count += 1
                    self.log_progress(event_count)

                if self.should_stop(event_count):
                    break

            self.flush_events()

            # Update timestamp for next incremental run
            if event_count > 0 or not last_timestamp:
                self.set_last_timestamp(current_time)
                self.logger.info(
                    "Updated checkpoint timestamp: {0}".format(current_time))

            self.log_completion(event_count)
        except Exception as e:
            self.logger.error(
                "Error processing vulnerability feed: {0}".format(
                    str(e)))

        return event_count


class VulnerabilityNoInfoProcessor(BaseFeedProcessor):

    def __init__(self, tenable_client, checkpoint_mgr,
                 hec_handler, batch_size=5000, max_events=0):
        super(
            VulnerabilityNoInfoProcessor,
            self).__init__(
            tenable_client,
            checkpoint_mgr,
            hec_handler,
            "Informational Vulnerabilities",
            "tenableio_vulnerability_no_info",
            "tenable:io:vulnerability:info",
            "vulnerability_info",
            batch_size,
            max_events)

    def process(self):
        self.log_start()
        event_count = 0

        try:
            last_timestamp = self.get_last_timestamp()

            self.logger.info(
                "Initiating informational vulnerability export (severity: info)...")

            # Optimized export parameters
            export_kwargs = {
                'severity': ['info'],
                'num_assets': 2000,
                'include_unlicensed': True,
                'timeout': 3600
            }

            if last_timestamp and last_timestamp > 0:
                export_kwargs['since'] = int(last_timestamp)
                self.logger.info(
                    "Incremental export since: {0}".format(last_timestamp))

            current_time = int(time.time())

            for vuln in _safe_export_with_retry(
                lambda: self.tenable.exports.vulns(**export_kwargs),
                "Informational Vulnerabilities"
            ):
                vuln_key = "{0}_{1}_{2}_{3}".format(
                    vuln.get('asset', {}).get('uuid', 'unknown'),
                    vuln.get('plugin', {}).get('id', 'unknown'),
                    vuln.get('port', {}).get('port', '0'),
                    vuln.get('port', {}).get('protocol', 'tcp')
                )

                if self.is_processed(vuln_key):
                    continue

                if self.send_event(vuln, item_id=vuln_key):
                    event_count += 1
                    self.log_progress(event_count)

                if self.should_stop(event_count):
                    break

            self.flush_events()

            if event_count > 0 or not last_timestamp:
                self.set_last_timestamp(current_time)

            self.log_completion(event_count)
        except Exception as e:
            self.logger.error(
                "Error processing informational vulnerability feed: {0}".format(
                    str(e)))

        return event_count


class VulnerabilitySelfScanProcessor(BaseFeedProcessor):

    def __init__(self, tenable_client, checkpoint_mgr,
                 hec_handler, batch_size=5000, max_events=0):
        super(
            VulnerabilitySelfScanProcessor,
            self).__init__(
            tenable_client,
            checkpoint_mgr,
            hec_handler,
            "Agent-Based Vulnerabilities",
            "tenableio_vulnerability_self_scan",
            "tenable:io:vulnerability:self_scan",
            "vulnerability_self_scan",
            batch_size,
            max_events)

    def process(self):
        self.log_start()
        event_count = 0

        try:
            last_timestamp = self.get_last_timestamp()

            self.logger.info("Initiating agent-based vulnerability export...")

            # Optimized export with state='OPEN' for agent-scanned vulns
            export_kwargs = {
                'state': 'OPEN',
                'num_assets': 2000,
                'include_unlicensed': True,
                'timeout': 3600
            }

            if last_timestamp and last_timestamp > 0:
                export_kwargs['since'] = int(last_timestamp)
                self.logger.info(
                    "Incremental export since: {0}".format(last_timestamp))

            current_time = int(time.time())

            for vuln in _safe_export_with_retry(
                lambda: self.tenable.exports.vulns(**export_kwargs),
                "Agent-Based Vulnerabilities"
            ):
                asset_info = vuln.get('asset', {})
                if not asset_info.get('has_agent', False):
                    continue

                vuln_key = "{0}_{1}_{2}_{3}".format(
                    asset_info.get('uuid', 'unknown'),
                    vuln.get('plugin', {}).get('id', 'unknown'),
                    vuln.get('port', {}).get('port', '0'),
                    vuln.get('port', {}).get('protocol', 'tcp')
                )

                if self.is_processed(vuln_key):
                    continue

                if self.send_event(vuln, item_id=vuln_key):
                    event_count += 1
                    self.log_progress(event_count)

                if self.should_stop(event_count):
                    break

            self.flush_events()

            if event_count > 0 or not last_timestamp:
                self.set_last_timestamp(current_time)

            self.log_completion(event_count)
        except Exception as e:
            self.logger.error(
                "Error processing agent-based vulnerability feed: {0}".format(str(e)))

        return event_count


class FixedVulnerabilityProcessor(BaseFeedProcessor):

    def __init__(self, tenable_client, checkpoint_mgr,
                 hec_handler, batch_size=5000, max_events=0):
        super(
            FixedVulnerabilityProcessor,
            self).__init__(
            tenable_client,
            checkpoint_mgr,
            hec_handler,
            "Fixed Vulnerabilities",
            "tenableio_fixed_vulnerability",
            "tenable:io:vulnerability:fixed",
            "fixed_vulnerability",
            batch_size,
            max_events)

    def process(self):
        self.log_start()
        event_count = 0

        try:
            previous_vulns = self.get_processed_ids()
            self.logger.info(
                "Found {0} vulnerabilities in previous checkpoint".format(
                    len(previous_vulns)))

            current_vulns = set()
            self.logger.info(
                "Fetching current vulnerabilities from Tenable...")
            self.logger.info(
                "(This may take several minutes for large environments)")

            # Optimized export parameters
            export_kwargs = {
                'state': 'OPEN',
                'num_assets': 2000,
                'include_unlicensed': True,
                'timeout': 3600
            }

            for vuln in _safe_export_with_retry(
                lambda: self.tenable.exports.vulns(**export_kwargs),
                "Fixed Vulnerabilities"
            ):
                vuln_key = "{0}_{1}_{2}_{3}".format(
                    vuln.get('asset', {}).get('uuid', 'unknown'),
                    vuln.get('plugin', {}).get('id', 'unknown'),
                    vuln.get('port', {}).get('port', '0'),
                    vuln.get('port', {}).get('protocol', 'tcp')
                )
                current_vulns.add(vuln_key)

            self.logger.info(
                "Found {0} current vulnerabilities".format(
                    len(current_vulns)))
            fixed_vulns = previous_vulns - current_vulns

            if fixed_vulns:
                self.logger.info(
                    "Detected {0} fixed vulnerabilities".format(
                        len(fixed_vulns)))
                for vuln_key in fixed_vulns:
                    parts = vuln_key.split('_')
                    fix_event = {
                        'vulnerability_key': vuln_key,
                        'asset_uuid': parts[0] if len(parts) > 0 else 'unknown',
                        'plugin_id': parts[1] if len(parts) > 1 else 'unknown',
                        'port': parts[2] if len(parts) > 2 else '0',
                        'protocol': parts[3] if len(parts) > 3 else 'tcp',
                        'event_type': 'vulnerability_fixed',
                        'detected_at': int(
                            time.time())}
                    if self.send_event(fix_event):
                        event_count += 1
                        self.log_progress(event_count)

                    if self.should_stop(event_count):
                        break
            else:
                self.logger.info("No fixed vulnerabilities detected")

            for vuln_key in current_vulns:
                self.mark_processed(vuln_key)

            self.flush_events()
            self.log_completion(event_count)
        except Exception as e:
            self.logger.error(
                "Error processing fixed vulnerability feed: {0}".format(
                    str(e)))

        return event_count
